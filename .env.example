# LLM Configuration (OpenAI Compatible Proxy)
# Base URL for OpenAI compatible API (e.g., OneAPI, LiteLLM, New API)
LLM_BASE_URL=http://127.0.0.1:8045/v1

# API key for the LLM service
LLM_API_KEY=your_api_key_here

# Model name to use (depends on your proxy configuration)
LLM_MODEL=gemini-3-flash

# MCP Services
# Amap (Gaode) MCP SSE URL
AMAP_MCP_URL=https://mcp.amap.com/sse?key=your_amap_key

# Weather MCP Service (self-hosted)
WEATHER_MCP_URL=http://localhost:8083/sse

# Xiaohongshu MCP (via Smithery)
# Xiaohongshu MCP (jobsonlook-xhs-mcp)
XHS_COOKIE=your_xhs_cookie_here
# Optional: directory where xhs-mcp is located
XHS_MCP_DIR=/path/to/xhs-mcp
XHS_PROFILE=your_profile_id

# Server Configuration
HOST=0.0.0.0
PORT=8182
